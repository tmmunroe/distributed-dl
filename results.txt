[0]
Using unbounded batch size per gpu generator
BatchSize:  32 ... BatchSizePerGpu:  32
Files already downloaded and verified
Time creating dataset object:  0.8342254549988866
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 3.493575951013554, Training Time: 34.95447781100302, Total Time: 38.482108166001126, Loss: 1.6617019964224846, Acc: 0.39622

BatchSize:  128 ... BatchSizePerGpu:  128
Files already downloaded and verified
Time creating dataset object:  0.8196528469998157
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 7.767765242993846, Training Time: 12.43377107698143, Total Time: 20.23774592799964, Loss: 1.486044209830615, Acc: 0.4554

BatchSize:  512 ... BatchSizePerGpu:  512
Files already downloaded and verified
Time creating dataset object:  0.8289492910007539
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 9.715568321003957, Training Time: 7.519045663008001, Total Time: 17.26950302699879, Loss: 1.8420441114541255, Acc: 0.35102

BatchSize:  2048 ... BatchSizePerGpu:  2048
Files already downloaded and verified
Time creating dataset object:  0.8054896090015973
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 9.797147674998996, Training Time: 8.429805645995657, Total Time: 18.28060757500134, Loss: 1.8816949266653795, Acc: 0.311

BatchSize:  8192 ... BatchSizePerGpu:  8192
Files already downloaded and verified
Time creating dataset object:  0.8867497539995384
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 10.862841288004347, Training Time: 8.584886251999706, Total Time: 19.49504228099977, Loss: 4.8622749745845795, Acc: 0.195

BatchSize:  32768 ... BatchSizePerGpu:  32768
Files already downloaded and verified
Time creating dataset object:  0.8243203570000333
Epoch: 1 of 2
Failed at batch_size_per_gpu 32768 with error: 
CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 14.56 GiB total capacity; 13.01 GiB already allocated; 106.44 MiB free; 13.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
      gpus    batch_size_per_gpu      time    communication_time    computation_time    speedup
--  ------  --------------------  --------  --------------------  ------------------  ---------
 0       1                    32  34.9545                      0            34.9545           1
 1       1                   128  12.4338                      0            12.4338           1
 2       1                   512   7.51905                     0             7.51905          1
 3       1                  2048   8.42981                     0             8.42981          1
 4       1                  8192   8.58489                     0             8.58489          1
--------------------------

--------------------------

Using batch sizes per gpu [32, 128, 512, 2048, 8192] for multi gpus...
--------------------------

--------------------------

[0, 1]
BatchSize:  64 ... BatchSizePerGpu:  32
Files already downloaded and verified
Time creating dataset object:  0.8904491310004232
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 2.7349292330145545, Training Time: 43.30290167001476, Total Time: 46.08090857999923, Loss: 1.6758280450509122, Acc: 0.38422

BatchSize:  256 ... BatchSizePerGpu:  128
Files already downloaded and verified
Time creating dataset object:  0.8191877240005851
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 5.905470106999928, Training Time: 17.297916446997988, Total Time: 23.245882558998346, Loss: 1.698385609588042, Acc: 0.39086

BatchSize:  1024 ... BatchSizePerGpu:  512
Files already downloaded and verified
Time creating dataset object:  0.8015305329990952
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 10.833980311006599, Training Time: 6.00173296399953, Total Time: 16.879473253999095, Loss: 1.5934132075309753, Acc: 0.40764

BatchSize:  4096 ... BatchSizePerGpu:  2048
Files already downloaded and verified
Time creating dataset object:  0.8104146240002592
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 11.682553466998797, Training Time: 5.339467269001034, Total Time: 17.06897923299948, Loss: 3.6640803813934326, Acc: 0.13016

BatchSize:  16384 ... BatchSizePerGpu:  8192
Files already downloaded and verified
Time creating dataset object:  0.8241423170002236
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 16.324937417997717, Training Time: 4.586075750999953, Total Time: 20.977662892999433, Loss: 2.8846810817718507, Acc: 0.20832

      gpus    batch_size_per_gpu      time    communication_time    computation_time    speedup
--  ------  --------------------  --------  --------------------  ------------------  ---------
 0       2                    32  43.3029              8.30648              34.9964    0.807209
 1       2                   128  17.2979              3.23667              14.0612    0.718802
 2       2                   512   6.00173             0.945905              5.05583   1.25281
 3       2                  2048   5.33947             0.216866              5.1226    1.57877
 4       2                  8192   4.58608             0.0505201             4.53556   1.87195
--------------------------

--------------------------

[0, 1, 2, 3]
BatchSize:  128 ... BatchSizePerGpu:  32
Files already downloaded and verified
Time creating dataset object:  0.8141613170009805
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 1.8004557090007438, Training Time: 36.771982674001265, Total Time: 38.631458546999056, Loss: 1.5579245735187919, Acc: 0.43266

BatchSize:  512 ... BatchSizePerGpu:  128
Files already downloaded and verified
Time creating dataset object:  0.8131712119993608
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 7.8452660619987, Training Time: 14.13448277099451, Total Time: 22.041627257000073, Loss: 1.681688331594371, Acc: 0.386

BatchSize:  2048 ... BatchSizePerGpu:  512
Files already downloaded and verified
Time creating dataset object:  0.8191277469995839
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 12.259446412992475, Training Time: 4.671653673000037, Total Time: 16.99146463299985, Loss: 2.26595499423834, Acc: 0.2412

BatchSize:  8192 ... BatchSizePerGpu:  2048
Files already downloaded and verified
Time creating dataset object:  0.8563206720009475
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 13.118891213998722, Training Time: 3.308365392000269, Total Time: 16.499337040000682, Loss: 4.470420658588409, Acc: 0.19082

BatchSize:  32768 ... BatchSizePerGpu:  8192
Files already downloaded and verified
Time creating dataset object:  0.8153627770007006
Epoch: 1 of 2
Epoch: 2 of 2
Epoch 2 Metrics:
Epoch 2 DataLoader Time: 18.382631528000275, Training Time: 2.568331422000483, Total Time: 21.05052230000001, Loss: 1.5785699685414631, Acc: 0.21158

      gpus    batch_size_per_gpu      time    communication_time    computation_time    speedup
--  ------  --------------------  --------  --------------------  ------------------  ---------
 0       4                    32  36.772               7.22082              29.5512    0.950574
 1       4                   128  14.1345              3.2102               10.9243    0.879676
 2       4                   512   4.67165             0.77962               3.89203   1.6095
 3       4                  2048   3.30837             0.19796               3.11041   2.54803
 4       4                  8192   2.56833             0.0268073             2.54152   3.34259
--------------------------

--------------------------

Files already downloaded and verified
Time creating dataset object:  0.8250754839991714
Epoch: 1 of 5
Epoch: 2 of 5
Epoch: 3 of 5
Epoch: 4 of 5
Epoch: 5 of 5
Large Batch Training Results:
   gpus  batch_size_per_gpu  total_batch_size  ...      time  accuracy      loss
0     4                8192             32768  ...  2.571504   0.27352  2.299754

[1 rows x 7 columns]
--------------------------

--------------------------

Scaling learning rate by:  256.0
Using scaled learning rate:  25.6
Using warmup epochs:  3
Files already downloaded and verified
Time creating dataset object:  0.8169701419992634
Adjusting learning rate of group 0 to 8.5333e+00.
Epoch: 1 of 5
Adjusting learning rate of group 0 to 1.4222e+01.
Epoch: 2 of 5
Adjusting learning rate of group 0 to 1.9911e+01.
Epoch: 3 of 5
Adjusting learning rate of group 0 to 2.5600e+01.
Epoch: 4 of 5
Adjusting learning rate of group 0 to 2.5600e+01.
Epoch: 5 of 5
Adjusting learning rate of group 0 to 2.5600e+01.
Large Batch Training with Warmup and Linearly Scaled Learning Rate Results:
   gpus  batch_size_per_gpu  total_batch_size  ...      time  accuracy          loss
0     4                8192             32768  ...  2.563219   0.10146  10005.510905

[1 rows x 9 columns]
--------------------------

--------------------------

